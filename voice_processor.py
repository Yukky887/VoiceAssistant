# voice_processor.py
import webrtcvad
import pvporcupine
import pvcheetah
import pyaudio
import numpy as np
import threading
import time
import queue
from Levenshtein import distance as lev_distance
import speech_recognition as sr


class VoiceProcessor:
    def __init__(self, wake_words=["Ð´Ð¶Ð°Ñ€Ð²Ð¸Ñ", "jarvis"], sensitivity=0.7):
        self.vad = webrtcvad.Vad(2)  # Ð¡Ñ€ÐµÐ´Ð½Ð¸Ð¹ Ñ€ÐµÐ¶Ð¸Ð¼
        self.sample_rate = 16000
        self.frame_duration = 30  # ms
        self.frame_size = int(self.sample_rate * self.frame_duration / 1000)

        # Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Porcupine Ð´Ð»Ñ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð³Ð¾ wake word
        try:
            self.porcupine = pvporcupine.create(
                access_key="Uik+LoHMAJvsWvBX+VlvnqdwNzdAdDy3u6buANhykdyT0UZ/AnNnmw==",  # Ð’Ð°Ñˆ ÐºÐ»ÑŽÑ‡
                keywords=["jarvis"]  # ÐÐ½Ð³Ð»Ð¸Ð¹ÑÐºÐ°Ñ Ð²ÐµÑ€ÑÐ¸Ñ
            )
            self.use_porcupine = True
            print("âœ… Porcupine Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½ Ð´Ð»Ñ 'jarvis'")
        except Exception as e:
            print(f"âš ï¸ Porcupine Ð½Ðµ Ð¸Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½: {e}")
            self.use_porcupine = False

        # Ð”Ð»Ñ Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ wake word Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ðµ
        self.wake_words = [w.lower() for w in wake_words]
        self.sensitivity = sensitivity
        self.is_listening = False
        self.audio_queue = queue.Queue()
        self.callback = None

        # Ð”Ð»Ñ Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()

        # ÐÐ°ÑÑ‚Ñ€Ð¾Ð¹ÐºÐ° Ð°ÑƒÐ´Ð¸Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°
        self.audio = pyaudio.PyAudio()
        self.stream = None

        # Ð‘ÑƒÑ„ÐµÑ€ Ð´Ð»Ñ Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ
        self.speech_buffer = b""
        self.speech_timeout = 0

    def start_listening(self, callback):
        """Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÑ‚ Ð¿Ñ€Ð¾ÑÐ»ÑƒÑˆÐ¸Ð²Ð°Ð½Ð¸Ðµ Ð² Ñ„Ð¾Ð½Ð¾Ð²Ð¾Ð¼ Ñ€ÐµÐ¶Ð¸Ð¼Ðµ"""
        self.callback = callback
        self.is_listening = True

        # ÐšÐ°Ð»Ð¸Ð±Ñ€ÑƒÐµÐ¼ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½ Ð´Ð»Ñ Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ
        print("ðŸ”§ ÐšÐ°Ð»Ð¸Ð±Ñ€ÑƒÑŽ Ð¼Ð¸ÐºÑ€Ð¾Ñ„Ð¾Ð½ Ð´Ð»Ñ Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ...")
        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source, duration=1)

        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº Ð´Ð»Ñ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð°ÑƒÐ´Ð¸Ð¾
        self.process_thread = threading.Thread(target=self._process_audio)
        self.process_thread.daemon = True
        self.process_thread.start()

        # Ð—Ð°Ð¿ÑƒÑÐºÐ°ÐµÐ¼ Ð¿Ð¾Ñ‚Ð¾Ðº Ð´Ð»Ñ Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð°ÑƒÐ´Ð¸Ð¾
        self.record_thread = threading.Thread(target=self._record_audio)
        self.record_thread.daemon = True
        self.record_thread.start()

        print("ðŸŽ¯ Ð“Ð¾Ð»Ð¾ÑÐ¾Ð²Ð¾Ð¹ Ð¿Ñ€Ð¾Ñ†ÐµÑÑÐ¾Ñ€ Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½ (Ñ€ÑƒÑÑÐºÐ¸Ð¹ + Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ wake words)")

    def stop_listening(self):
        """ÐžÑÑ‚Ð°Ð½Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÑ‚ Ð¿Ñ€Ð¾ÑÐ»ÑƒÑˆÐ¸Ð²Ð°Ð½Ð¸Ðµ"""
        self.is_listening = False
        if self.stream:
            self.stream.stop_stream()
            self.stream.close()
        if self.audio:
            self.audio.terminate()

    def _record_audio(self):
        """Ð—Ð°Ð¿Ð¸ÑÑ‹Ð²Ð°ÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ Ð² Ð¾Ñ‚Ð´ÐµÐ»ÑŒÐ½Ð¾Ð¼ Ð¿Ð¾Ñ‚Ð¾ÐºÐµ"""
        try:
            self.stream = self.audio.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.frame_size,
                stream_callback=self._audio_callback
            )
            self.stream.start_stream()

            print("ðŸŽ¤ ÐÑƒÐ´Ð¸Ð¾ Ð¿Ð¾Ñ‚Ð¾Ðº Ð·Ð°Ð¿ÑƒÑ‰ÐµÐ½...")

            while self.stream.is_active() and self.is_listening:
                time.sleep(0.1)

        except Exception as e:
            print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð·Ð°Ð¿Ð¸ÑÐ¸ Ð°ÑƒÐ´Ð¸Ð¾: {e}")

    def _audio_callback(self, in_data, frame_count, time_info, status):
        """Callback Ð´Ð»Ñ Ð°ÑƒÐ´Ð¸Ð¾ Ð¿Ð¾Ñ‚Ð¾ÐºÐ°"""
        self.audio_queue.put(in_data)
        return (in_data, pyaudio.paContinue)

    def _process_audio(self):
        """ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ wake word detection"""
        consecutive_speech = 0
        audio_chunks = []

        print("ðŸ”„ ÐÐ°Ñ‡Ð¸Ð½Ð°ÑŽ Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÑƒ Ð°ÑƒÐ´Ð¸Ð¾...")

        while self.is_listening:
            try:
                # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð°ÑƒÐ´Ð¸Ð¾ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¸Ð· Ð¾Ñ‡ÐµÑ€ÐµÐ´Ð¸
                frame = self.audio_queue.get(timeout=0.5)

                # 1. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ðµ wake word Ñ‡ÐµÑ€ÐµÐ· Porcupine
                if self.use_porcupine:
                    pcm = np.frombuffer(frame, dtype=np.int16)
                    keyword_index = self.porcupine.process(pcm)
                    if keyword_index >= 0:
                        print("ðŸŽ¯ ÐÐ½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ðµ wake word 'jarvis' Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾!")
                        if self.callback:
                            self.callback("wake_word_detected")
                        continue

                # 2. ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ VAD Ð´Ð»Ñ Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ð²Ð°Ð½Ð¸Ñ
                is_speech = self.vad.is_speech(frame, self.sample_rate)

                if is_speech:
                    consecutive_speech += 1
                    audio_chunks.append(frame)

                    # Ð•ÑÐ»Ð¸ Ð½Ð°ÐºÐ¾Ð¿Ð¸Ð»Ð¸ Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ñ€ÐµÑ‡Ð¸, Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ñ€Ð°ÑÐ¿Ð¾Ð·Ð½Ð°Ñ‚ÑŒ
                    if consecutive_speech >= 10:  # ~300ms Ñ€ÐµÑ‡Ð¸
                        audio_data = b''.join(audio_chunks)
                        text = self._speech_to_text(audio_data)
                        if text and self._check_russian_wake_word(text):
                            print(f"ðŸŽ¯ Ð ÑƒÑÑÐºÐ¾Ðµ wake word Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾: {text}")
                            if self.callback:
                                self.callback("wake_word_detected")
                            audio_chunks = []
                            consecutive_speech = 0
                else:
                    # Ð¡Ð±Ñ€Ð¾Ñ Ð¿Ñ€Ð¸ Ñ‚Ð¸ÑˆÐ¸Ð½Ðµ
                    if consecutive_speech > 0:
                        consecutive_speech -= 1
                    if consecutive_speech <= 0:
                        audio_chunks = []
                        consecutive_speech = 0

            except queue.Empty:
                continue
            except Exception as e:
                print(f"âŒ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð±Ñ€Ð°Ð±Ð¾Ñ‚ÐºÐ¸ Ð°ÑƒÐ´Ð¸Ð¾: {e}")
                time.sleep(0.1)

    def _speech_to_text(self, audio_data):
        """ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÑ‚ Ð°ÑƒÐ´Ð¸Ð¾ Ð² Ñ‚ÐµÐºÑÑ‚ Ð´Ð»Ñ Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ wake word"""
        try:
            # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ AudioData Ð¾Ð±ÑŠÐµÐºÑ‚ Ð´Ð»Ñ speech_recognition
            audio = sr.AudioData(audio_data, self.sample_rate, 2)
            text = self.recognizer.recognize_google(audio, language="ru-RU")
            return text.lower().strip()
        except sr.UnknownValueError:
            return None
        except Exception as e:
            return None

    def _check_russian_wake_word(self, text):
        """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚ Ñ€ÑƒÑÑÐºÐ¾Ðµ wake word Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð›ÐµÐ²ÐµÐ½ÑˆÑ‚ÐµÐ¹Ð½Ð°"""
        if not text:
            return False

        for wake_word in self.wake_words:
            # ÐŸÑ€Ð¾ÑÑ‚Ð°Ñ Ð¿Ñ€Ð¾Ð²ÐµÑ€ÐºÐ° Ð²Ñ…Ð¾Ð¶Ð´ÐµÐ½Ð¸Ñ
            if wake_word in text:
                return True

            # ÐŸÑ€Ð¾Ð²ÐµÑ€ÐºÐ° Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ñ Ð›ÐµÐ²ÐµÐ½ÑˆÑ‚ÐµÐ¹Ð½Ð° Ð´Ð»Ñ Ð¾Ð¿ÐµÑ‡Ð°Ñ‚Ð¾Ðº
            words = text.split()
            for word in words:
                dist = lev_distance(wake_word, word)
                max_allowed_distance = max(1, len(wake_word) // 3)
                if dist <= max_allowed_distance:
                    print(f"âœ… Ð ÑƒÑÑÐºÐ¾Ðµ wake word '{wake_word}' Ð¾Ð±Ð½Ð°Ñ€ÑƒÐ¶ÐµÐ½Ð¾ (Ñ€Ð°ÑÑÑ‚Ð¾ÑÐ½Ð¸Ðµ: {dist})")
                    return True

        return False